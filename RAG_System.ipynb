{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8933396",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LOQ\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from FlagEmbedding import FlagReranker\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.prompts import ChatPromptTemplate, format_document\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "import requests\n",
    "import sys\n",
    "from langchain_core.prompts import ChatPromptTemplate, format_document\n",
    "from langchain.prompts.prompt import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18df26a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GROQ_API_KEY\"] = \"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\"  \n",
    "\n",
    "model_name = \"BAAI/bge-large-en-v1.5\"\n",
    "encode_kwargs = {'normalize_embeddings': True} \n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_norm = HuggingFaceEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs={'device': DEVICE},\n",
    "    encode_kwargs=encode_kwargs)\n",
    "\n",
    "db3 = Chroma(persist_directory=\"db\", embedding_function=model_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9141dddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import requests\n",
    "from typing import List, Optional\n",
    "retriever = db3.as_retriever(search_kwargs={\"k\": 100})\n",
    "def find_first_string(obj) -> Optional[str]:\n",
    "    if isinstance(obj, str):\n",
    "        return obj\n",
    "    elif isinstance(obj, dict):\n",
    "        for v in obj.values():\n",
    "            found = find_first_string(v)\n",
    "            if found:\n",
    "                return found\n",
    "    elif isinstance(obj, list):\n",
    "        for item in obj:\n",
    "            found = find_first_string(item)\n",
    "            if found:\n",
    "                return found\n",
    "    return None\n",
    "\n",
    "def get_answer(input_text: str, max_retries: int = 10, backoff_sec: float = 2.0) -> str:\n",
    "    url = 'https://api.groq.com/openai/v1/chat/completions'\n",
    "    headers = {\n",
    "        'Authorization': 'Bearer ' + os.environ[\"GROQ_API_KEY\"],\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "\n",
    "    data = {\n",
    "        \"model\": \"llama3-70b-8192\",\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": input_text}\n",
    "        ],\n",
    "        \"temperature\": 0.7,\n",
    "        \"max_tokens\": 100,\n",
    "        \"top_p\": 0.95\n",
    "    }\n",
    "\n",
    "    for attempt in range(1, max_retries + 1):\n",
    "        response = requests.post(url, headers=headers, json=data)\n",
    "        print(f\"Attempt {attempt} - Status: {response.status_code}\")\n",
    "\n",
    "        if response.status_code == 429:\n",
    "            # Rate limit exceeded, chờ rồi thử lại\n",
    "            retry_after = backoff_sec * attempt\n",
    "            print(f\"Rate limit reached. Retrying after {retry_after:.1f} seconds...\")\n",
    "            time.sleep(retry_after)\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            result = response.json()\n",
    "            print(\"Full JSON response:\", result)\n",
    "\n",
    "            if 'choices' in result and len(result['choices']) > 0:\n",
    "                message = result['choices'][0].get('message')\n",
    "                if message and 'content' in message:\n",
    "                    return message['content']\n",
    "\n",
    "            if 'text' in result:\n",
    "                return result['text']\n",
    "\n",
    "            if 'output' in result:\n",
    "                output = result['output']\n",
    "                return output if isinstance(output, str) else str(output)\n",
    "\n",
    "            any_text = find_first_string(result)\n",
    "            if any_text:\n",
    "                return any_text\n",
    "\n",
    "            return \"No valid response content found.\"\n",
    "\n",
    "        except Exception as e:\n",
    "            return f\"Error parsing response: {e}\"\n",
    "\n",
    "    return \"Failed to get valid response after retries.\"\n",
    "\n",
    "from langchain import PromptTemplate\n",
    "from typing import Any\n",
    "\n",
    "DEFAULT_DOCUMENT_PROMPT = PromptTemplate.from_template(template=\"{page_content}\")\n",
    "\n",
    "def combine_documents(docs: List[Any], document_prompt=DEFAULT_DOCUMENT_PROMPT, document_separator: str = \"\\n\\n\") -> str:\n",
    "    # docs có thể là List[Document] hoặc List[Tuple]\n",
    "    doc_strings = []\n",
    "    for doc in docs:\n",
    "        # Nếu doc có attribute page_content (Document của langchain)\n",
    "        if hasattr(doc, 'page_content'):\n",
    "            doc_str = document_prompt.format(page_content=doc.page_content)\n",
    "        elif isinstance(doc, (list, tuple)) and len(doc) > 1:\n",
    "            doc_str = str(doc[1])\n",
    "        else:\n",
    "            doc_str = str(doc)\n",
    "        doc_strings.append(doc_str)\n",
    "    return document_separator.join(doc_strings)\n",
    "\n",
    "def split_questions(text: str, delimiter: str = '?') -> List[str]:\n",
    "    if delimiter not in text:\n",
    "        return [text.strip()]  # Trả về nguyên văn nếu không có dấu câu hỏi\n",
    "    questions = text.split(delimiter)\n",
    "    cleaned_questions = []\n",
    "    for q in questions:\n",
    "        q = q.strip()\n",
    "        if not q:\n",
    "            continue\n",
    "        # Lấy phần sau dấu chấm đầu tiên nếu có, rồi thêm lại dấu hỏi\n",
    "        if \". \" in q:\n",
    "            q = q.split(\". \", 1)[-1]\n",
    "        cleaned_questions.append(q + delimiter)\n",
    "    return cleaned_questions\n",
    "def combine_documents_2(docs, document_separator=\"\\n\\n\"):\n",
    "    combined_docs = []\n",
    "    for doc in docs:\n",
    "        combined_docs.append(doc[1])\n",
    "    return document_separator.join(combined_docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b314c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sử dụng Retriever (thường)\n",
    "def _unique_documents(documents):\n",
    "    return [doc for i, doc in enumerate(documents) if doc not in documents[:i]]\n",
    "with open('Data_test/test_questions.csv', 'r') as file:\n",
    "    questions = file.readlines()\n",
    "for question in questions:\n",
    "    docs = retriever.invoke(question)\n",
    "\n",
    "    prompt_start = \"\"\"You are an assistant for question-answering tasks and the questions are related to the University of Pittsburgh. Do not exceed one sentence for the answer. Do not be verbose when generating the answer. Give out the answer directly even if it does not form a coherent sentence.    \"\"\"\n",
    "    context = combine_documents(docs[:10])\n",
    "    input_text = prompt_start + \"Question: \" + question + \"Context: \" + context + \"Answer: \"\n",
    "    time.sleep(2)\n",
    "    print(question)\n",
    "\n",
    "    answer = get_answer(input_text)\n",
    "    with open('system_output_1.txt', 'a', encoding='utf-8') as output_file:\n",
    "        output_file.write(f'{answer}\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

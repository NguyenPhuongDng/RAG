{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3144b7de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LOQ\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from FlagEmbedding import FlagReranker\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.prompts import ChatPromptTemplate, format_document\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "import requests\n",
    "import sys\n",
    "from langchain_core.prompts import ChatPromptTemplate, format_document\n",
    "from langchain.prompts.prompt import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63babe68",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TOGETHER_API_KEY\"] = \"414229540a05a7ce253fd2bfc33d221a19ff3277c6bd7bde1056eca4bc0f18ae\"  \n",
    "\n",
    "model_name = \"BAAI/bge-large-en-v1.5\"\n",
    "encode_kwargs = {'normalize_embeddings': True} \n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_norm = HuggingFaceEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs={'device': DEVICE},\n",
    "    encode_kwargs=encode_kwargs)\n",
    "\n",
    "db3 = Chroma(persist_directory=\"db\", embedding_function=model_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0e5e412",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db3.as_retriever(search_kwargs={\"k\": 100})\n",
    "def get_answer(input_text) -> str:\n",
    "    url = 'https://api.together.xyz/inference'\n",
    "    headers = {\n",
    "      'Authorization': 'Bearer ' + os.environ[\"TOGETHER_API_KEY\"],\n",
    "      'accept': 'application/json',\n",
    "      'content-type': 'application/json'\n",
    "    }\n",
    "    time.sleep(10)  # Nghỉ 10 giây để tránh rate limit\n",
    "\n",
    "    data = {\n",
    "      \"model\": \"meta-llama/Llama-3.3-70B-Instruct-Turbo-Free\",\n",
    "      \"prompt\": input_text,\n",
    "      \"max_tokens\": 100,\n",
    "      \"temperature\": 0.7,\n",
    "      \"top_p\": 0.7,\n",
    "      \"top_k\": 50,\n",
    "      \"repetition_penalty\": 1\n",
    "\n",
    "    }\n",
    "    \n",
    "    response = requests.post(url, json=data, headers=headers)\n",
    "    print(response.status_code)\n",
    "    print(response.json())\n",
    "\n",
    "    text = response.json()['output']['choices'][0]['text']\n",
    "    print(text)\n",
    "    return text\n",
    "\n",
    "DEFAULT_DOCUMENT_PROMPT = PromptTemplate.from_template(template=\"{page_content}\")\n",
    "\n",
    "def combine_documents(docs, document_prompt=DEFAULT_DOCUMENT_PROMPT, document_separator=\"\\n\\n\"):\n",
    "    doc_strings = [format_document(doc, document_prompt) for doc in docs]\n",
    "    return document_separator.join(doc_strings)\n",
    "\n",
    "def combine_documents_2(docs, document_separator=\"\\n\\n\"):\n",
    "    combined_docs = []\n",
    "    for doc in docs:\n",
    "        combined_docs.append(doc[1])\n",
    "    return document_separator.join(combined_docs)\n",
    "\n",
    "def split_questions(string, delimiter='?'):\n",
    "    questions = string.split(delimiter)\n",
    "    questions = [question.strip().split(\". \", 1)[-1] + delimiter for question in questions]\n",
    "    return questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d27804",
   "metadata": {},
   "source": [
    "RAG thường"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba40a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sử dụng Retriever (thường)\n",
    "def _unique_documents(documents):\n",
    "    return [doc for i, doc in enumerate(documents) if doc not in documents[:i]]\n",
    "with open('test.csv', 'r') as file:\n",
    "    questions = file.readlines()\n",
    "for question in questions:\n",
    "    docs = retriever.invoke(question)\n",
    "\n",
    "    prompt_start = \"\"\"You are an assistant for question-answering tasks and the questions are related to the University of Pittsburgh. Do not exceed one sentence for the answer. Do not be verbose when generating the answer. Give out the answer directly even if it does not form a coherent sentence.    \"\"\"\n",
    "    context = combine_documents(docs[:10])\n",
    "    input_text = prompt_start + \"Question: \" + question + \"Context: \" + context + \"Answer: \"\n",
    "    time.sleep(2)\n",
    "    print(question)\n",
    "\n",
    "    answer = get_answer(input_text)\n",
    "    with open('rag_answers.txt', 'a', encoding='utf-8') as output_file:\n",
    "        output_file.write(f'{answer}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3158838e",
   "metadata": {},
   "source": [
    "RAG + Reranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be4b580",
   "metadata": {},
   "outputs": [],
   "source": [
    "reranker = FlagReranker('BAAI/bge-reranker-large', use_fp16=True)\n",
    "\n",
    "with open('test.csv', 'r', encoding = 'utf-8') as file:\n",
    "    questions = file.readlines()\n",
    "for question in questions:\n",
    "    docs = retriever.invoke(question)\n",
    "\n",
    "    prompt_start = \"\"\"You are an assistant for question-answering tasks and the questions are related to the University of Pittsburgh. Do not exceed one sentence for the answer. Do not be verbose when generating the answer. Give out the answer directly even if it does not form a coherent sentence.    \"\"\"\n",
    "    docs_to_rerank = []\n",
    "    for i in range(len(docs)):\n",
    "        docs_to_rerank.append([question, str(docs[i])])\n",
    "    scores = reranker.compute_score(docs_to_rerank)\n",
    "\n",
    "    combined_data = list(zip(docs_to_rerank, scores))\n",
    "    sorted_data = sorted(combined_data, key=lambda x: x[1], reverse=True)\n",
    "    sorted_docs_to_rerank, sorted_scores = zip(*sorted_data)\n",
    "    top_k_docs = sorted_docs_to_rerank[:10]\n",
    "    context = combine_documents_2(top_k_docs)\n",
    "\n",
    "    input_text = prompt_start + \"Question: \" + question + \"Context: \" + context + \"Answer: \"\n",
    "    print(question)\n",
    "    time.sleep(2)\n",
    "\n",
    "    answer = get_answer(input_text)\n",
    "    with open('rag_reranker_answers.txt', 'a', encoding = 'utf-8') as output_file:\n",
    "        output_file.write(f'{answer}\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75f78af",
   "metadata": {},
   "source": [
    "RAG + reranker + multiquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7816f11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "delimiter = '?'\n",
    "\n",
    "with open('test.csv', 'r') as file:\n",
    "    questions = file.readlines()\n",
    "    \n",
    "for question in questions:\n",
    "    \n",
    "    input_text_for_ques = f\"\"\"\n",
    "    [TASK]: Write the below question in 3 different ways.\n",
    "    [QUESTION]: {question}\n",
    "    \"\"\"\n",
    "    \n",
    "    diff_questions = get_answer(input_text_for_ques)\n",
    "    \n",
    "    paraphrased_ques = split_questions(diff_questions, delimiter)\n",
    "    paraphrased_ques = paraphrased_ques[:-1]\n",
    "    print(paraphrased_ques)\n",
    "    \n",
    "    all_docs = []\n",
    "    for single_question in paraphrased_ques:\n",
    "        all_docs.extend(retriever.get_relevant_documents(single_question))\n",
    "        \n",
    "    all_docs.extend(retriever.get_relevant_documents(question))\n",
    "    \n",
    "    unique_docs = _unique_documents(all_docs)\n",
    "\n",
    "    prompt_start = \"\"\"You are an assistant for question-answering tasks and the questions are related to the University of Pittsburgh. Do not exceed one sentence for the answer. Do not be verbose when generating the answer. Give out the answer directly even if it does not form a coherent sentence.    \"\"\"\n",
    "\n",
    "    docs_to_rerank = []\n",
    "    for i in range(len(unique_docs)):\n",
    "        docs_to_rerank.append([question, str(unique_docs[i])])\n",
    "    scores = reranker.compute_score(docs_to_rerank)\n",
    "\n",
    "    combined_data = list(zip(docs_to_rerank, scores))\n",
    "    sorted_data = sorted(combined_data, key=lambda x: x[1], reverse=True)\n",
    "    sorted_docs_to_rerank, sorted_scores = zip(*sorted_data)\n",
    "    top_k_docs = sorted_docs_to_rerank[:10]\n",
    "    context = combine_documents_2(top_k_docs)\n",
    "\n",
    "    input_text = prompt_start + \"Question: \" + question + \"Context: \" + context + \"Answer: \"\n",
    "    print(question)\n",
    "    time.sleep(2)\n",
    "\n",
    "    answer = get_answer(input_text)\n",
    "    with open('rag_reranker__multiquery_answers.txt', 'a', encoding = 'utf-8') as output_file:\n",
    "        output_file.write(f'{answer}\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
